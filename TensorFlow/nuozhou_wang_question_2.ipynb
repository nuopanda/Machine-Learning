{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 -- Rain in Australia\n",
    "\n",
    "In this problem, we will build models to predict whether it's going to rain tomorrow.\n",
    "\n",
    "## 1. Data loading\n",
    "Different from Problem 1, this data set contains three different types of features. We need to specify them and later process them separately before feeding to the training session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_COLUMNS = ['Date']\n",
    "\n",
    "NUMERIC_COLUMNS = ['MinTemp','MaxTemp','Rainfall','Evaporation','Sunshine',\n",
    "  'WindGustSpeed','WindSpeed9am','WindSpeed3pm','Humidity9am','Humidity3pm',\n",
    "  'Pressure9am','Pressure3pm','Cloud9am','Cloud3pm','Temp9am','Temp3pm']\n",
    "\n",
    "CATEGORICAL_COLUMNS = ['Location','WindGustDir','WindDir9am','WindDir3pm','RainToday','RainTomorrow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load data in. The first line of the CSV file is the head, which is removed when loading. We also need to move the column \"RISK_MM\" that's excluded from the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.0\n",
       "1         0.0\n",
       "2         1.0\n",
       "3         0.2\n",
       "4         0.0\n",
       "         ... \n",
       "145454    0.0\n",
       "145455    0.0\n",
       "145456    0.0\n",
       "145457    0.0\n",
       "145458    NaN\n",
       "Name: RISK_MM, Length: 145459, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dftrain = pd.read_csv(\n",
    "  'weatherAUS.csv',\n",
    "  header=1,\n",
    "  names=['Date','Location','MinTemp','MaxTemp','Rainfall','Evaporation','Sunshine',\n",
    "    'WindGustDir','WindGustSpeed','WindDir9am','WindDir3pm','WindSpeed9am','WindSpeed3pm',\n",
    "    'Humidity9am','Humidity3pm','Pressure9am','Pressure3pm','Cloud9am','Cloud3pm',\n",
    "    'Temp9am','Temp3pm','RainToday','RISK_MM','RainTomorrow'])\n",
    "\n",
    "dftrain.pop('RISK_MM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
      "0  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
      "1  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
      "2  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
      "3  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
      "4  2008-12-06   Albury     14.6     29.7       0.2          NaN       NaN   \n",
      "\n",
      "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
      "0         WNW           44.0        NNW  ...        44.0         25.0   \n",
      "1         WSW           46.0          W  ...        38.0         30.0   \n",
      "2          NE           24.0         SE  ...        45.0         16.0   \n",
      "3           W           41.0        ENE  ...        82.0         33.0   \n",
      "4         WNW           56.0          W  ...        55.0         23.0   \n",
      "\n",
      "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
      "0       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
      "1       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
      "2       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
      "3       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
      "4       1009.2       1005.4       NaN       NaN     20.6     28.9         No   \n",
      "\n",
      "   RainTomorrow  \n",
      "0            No  \n",
      "1            No  \n",
      "2            No  \n",
      "3            No  \n",
      "4            No  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dftrain.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing\n",
    "\n",
    "### 2.1. Date type\n",
    "Sci-kit learn doesn't train against date type columns. In order to make it trainable, we need to either (1) convert date into numeric values (i.e. \"2019-01-01\" to int(20190101)); or (2) convert date into ordinals, so that dates are converted into sorted numbers in ascending order.\n",
    "\n",
    "Here we pick (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "for data_column in DATE_COLUMNS:\n",
    "  dftrain['Date'] = pd.to_datetime(dftrain['Date'])\n",
    "  dftrain['Date'] = dftrain['Date'].map(dt.datetime.toordinal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Numeric type\n",
    "For numeric columns, convert NaN and inf/-inf into the mean value of column. Again, we leave generalization at training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for column in NUMERIC_COLUMNS:\n",
    "  dftrain[column].fillna(dftrain[column].mean(), inplace=True)\n",
    "  dftrain[column].replace([np.inf, -np.inf], dftrain[column].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Categorical type\n",
    "For categorical columns, do label encoding. For the sake of space, we don't do one-hot encoding here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "for column in CATEGORICAL_COLUMNS:\n",
    "  dftrain[column] = preprocessing.LabelEncoder().fit_transform(dftrain[column].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Shuffling and split\n",
    "Here we shuffle the data, generate the label and split them under 80:20 (train:test) ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dftrain = shuffle(dftrain, random_state=8)\n",
    "\n",
    "dflabel = dftrain.pop('RainTomorrow')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dftrain, dflabel, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and testing data look like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainig features are:\n",
      "           Date  Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
      "57727   736092         5     12.7     17.2       0.4     5.468232  7.611178   \n",
      "48586   736070         9     10.2     23.0       0.6     5.468232  7.611178   \n",
      "100241  734106        22      9.7     20.9       0.0     3.600000  3.100000   \n",
      "\n",
      "        WindGustDir  WindGustSpeed  WindDir9am  ...  WindSpeed3pm  \\\n",
      "57727             5           54.0           5  ...          30.0   \n",
      "48586             6           30.0          11  ...          19.0   \n",
      "100241            2           48.0           2  ...          30.0   \n",
      "\n",
      "        Humidity9am  Humidity3pm  Pressure9am  Pressure3pm  Cloud9am  \\\n",
      "57727         100.0        100.0       1010.4       1004.4       7.0   \n",
      "48586          87.0         50.0       1022.3       1019.3       7.0   \n",
      "100241         68.0         59.0       1018.9       1016.2       8.0   \n",
      "\n",
      "        Cloud3pm  Temp9am  Temp3pm  RainToday  \n",
      "57727        8.0     13.0     14.5          0  \n",
      "48586        8.0     14.0     21.2          0  \n",
      "100241       7.0     14.7     19.5          0  \n",
      "\n",
      "[3 rows x 22 columns]\n",
      "Training labels are:\n",
      " 57727     1\n",
      "48586     1\n",
      "100241    0\n",
      "Name: RainTomorrow, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Trainig features are:\\n', x_train.head(3))\n",
    "print('Training labels are:\\n', y_train.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model training: a classification problem\n",
    "\n",
    "### 3.1. Logistic regression\n",
    "We first apply logistic regression with L1 and L2 regularization. Please be noted that training may be slower than Problem 1, due to the size of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic reg mean squared error for train: 0.3078\n",
      "logistic reg mean squared error for test: 0.3136\n",
      "logistic_reg score for train: 0.7592\n",
      "logistic_reg score for test: 0.7550\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "logistic_reg = LogisticRegression(solver='liblinear', max_iter=500, multi_class ='auto', random_state=23)\n",
    "\n",
    "logistic_reg.fit(x_train, y_train)\n",
    "\n",
    "print('logistic reg mean squared error for train: %.4f' % mean_squared_error(logistic_reg.predict(x_train), y_train))\n",
    "print('logistic reg mean squared error for test: %.4f' % mean_squared_error(logistic_reg.predict(x_test), y_test))\n",
    "\n",
    "print('logistic_reg score for train: %.4f' % logistic_reg.score(x_train, y_train))\n",
    "print('logistic_reg score for test: %.4f' % logistic_reg.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation is needed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for accuracy:  [0.75836112 0.75836112 0.75841325 0.75841325 0.75841325]\n",
      "Accuracy: 0.76 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(logistic_reg, dftrain, dflabel, cv=5, scoring='accuracy')\n",
    "\n",
    "print('Scores for accuracy: ', scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Gradient boosted tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic reg mean squared error for train: 0.1790\n",
      "logistic reg mean squared error for test: 0.1895\n",
      "logistic_reg score for train: 0.8495\n",
      "logistic_reg score for test: 0.8421\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "gb_tree_classifier = ensemble.GradientBoostingClassifier(\n",
    "  loss='deviance',\n",
    "  learning_rate=0.1,\n",
    "  n_estimators=200,\n",
    "  random_state=24,\n",
    "  max_depth=3,\n",
    "  max_features=None)\n",
    "\n",
    "gb_tree_classifier.fit(x_train, y_train)\n",
    "\n",
    "print('logistic reg mean squared error for train: %.4f' % mean_squared_error(gb_tree_classifier.predict(x_train), y_train))\n",
    "print('logistic reg mean squared error for test: %.4f' % mean_squared_error(gb_tree_classifier.predict(x_test), y_test))\n",
    "\n",
    "print('logistic_reg score for train: %.4f' % gb_tree_classifier.score(x_train, y_train))\n",
    "print('logistic_reg score for test: %.4f' % gb_tree_classifier.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation also verifies that results are consistent across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for accuracy:  [0.75836112 0.75836112 0.75841325 0.75841325 0.75841325]\n",
      "Accuracy: 0.76 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(logistic_reg, dftrain, dflabel, cv=5, scoring='accuracy')\n",
    "\n",
    "print('Scores for accuracy: ', scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, we found that the gradient boosted tree model was able to generate a better prediction with ~10% better accuracy, while maintaining a good balance in bias and variance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
