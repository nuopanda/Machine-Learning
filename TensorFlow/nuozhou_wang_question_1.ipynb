{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 -- Abalone Data Set\n",
    "\n",
    "In this problem, we will build models to predict the age of an abalone using the physical features.\n",
    "\n",
    "## 1. Data loading\n",
    "The data contains a total of 4177 samples, each with 8 features (7 continuous and 1 categorical) and 1 label. The features include Sex, Length, Diameter, Height, Whole weight, Shucked weight, Viscera weight, and Shell weight. The label of data is Rings, which can be translated into age by adding 1.5 to its values.\n",
    "\n",
    "First we load data in using pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dftrain = pd.read_csv(\n",
    "  'abalone.data',\n",
    "  names=['sex','length','diameter','height','whole_weight', 'shucked_weight','viscera_weight','shell_weight','rings'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sex  length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
      "0   M   0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
      "1   M   0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
      "2   F   0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
      "3   M   0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
      "4   I   0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
      "5   I   0.425     0.300   0.095        0.3515          0.1410          0.0775   \n",
      "\n",
      "   shell_weight  rings  \n",
      "0         0.150     15  \n",
      "1         0.070      7  \n",
      "2         0.210      9  \n",
      "3         0.155     10  \n",
      "4         0.055      7  \n",
      "5         0.120      8  \n"
     ]
    }
   ],
   "source": [
    "print(dftrain.head(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We manually pick several features and inspect their correlation with the label. It was observed that for many features, distribution of label values tends to expand when feature values gets larger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dflabel = dftrain.pop('rings')\n",
    "plt.plot(dftrain['whole_weight'], dflabel, \"b.\")\n",
    "plt.xlabel(\"$x_1$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
    "plt.axis([0, 2, 0, 15])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing\n",
    "In this section, a series of data preprocessing are applied before feeding it into the training session.\n",
    "\n",
    "### 2.1 Encoding\n",
    "Here we start with encoding categorical values into numeric ones. There are several popular ways to encode categorical values, such as label encoding, one-hot encoding and multi-hot encoding. In this case, we apply label encoding to the categorical features, because one-hot and multi-hot encoding creates additional columns and hence increases the total size of training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "dftrain['sex'] = preprocessing.LabelEncoder().fit_transform(dftrain['sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Shuffling\n",
    "We then shuffle the data set and pop out the label. Please be noted that generalization of data is not carried out during data preprocessing, as Sci-kit learn already provides a handy option of doing so at the training session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "dftrain = shuffle(dftrain, random_state=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features are now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex  length  diameter  height  whole_weight  shucked_weight  \\\n",
      "2123    0   0.290     0.210   0.075        0.2750          0.1130   \n",
      "3669    1   0.585     0.460   0.140        0.7635          0.3260   \n",
      "2218    2   0.495     0.390   0.150        0.8530          0.3285   \n",
      "2434    1   0.635     0.500   0.180        1.3190          0.5485   \n",
      "3599    2   0.735     0.555   0.220        2.3330          1.2395   \n",
      "\n",
      "      viscera_weight  shell_weight  \n",
      "2123          0.0675        0.0350  \n",
      "3669          0.1530        0.2650  \n",
      "2218          0.1890        0.2700  \n",
      "2434          0.2920        0.4900  \n",
      "3599          0.3645        0.6195  \n"
     ]
    }
   ],
   "source": [
    "print(dftrain.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    15\n",
      "1     7\n",
      "2     9\n",
      "3    10\n",
      "4     7\n",
      "Name: rings, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dflabel.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data split\n",
    "Now we split the data into train and test sets. Please be noted that we picked 80% as train set and 20% as the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dftrain, dflabel, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training: a regression problem\n",
    "\n",
    "### 3.1 Linear regression\n",
    "We first trained a model using a linear regressor from Sci-kit Learn with all default parameters, as the benchmark. As we've mentioned earlier, training data is normalized during this session (\"normalize=True\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_reg = LinearRegression(normalize=True)\n",
    "linear_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error for training: 10.2523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('Mean squared error for training: %.4f' % mean_squared_error(linear_reg.predict(x_train), y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is then evaluated as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error for evaluation: 10.8472\n"
     ]
    }
   ],
   "source": [
    "print('Mean squared error for evaluation: %.4f' % mean_squared_error(linear_reg.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid overfitting and underfitting, a cross-validation approach is also taken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for negative mean squared error:  [-20.57883148  -6.53420956 -11.92627395  -8.00908461  -7.55502367]\n",
      "Accuracy: -10.92 (+/- 10.33)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(linear_reg, dftrain, dflabel, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "print('Scores for negative mean squared error: ', scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also try a variety of other linear models using regularization like Lasso, Ridge and Elastic-net to fine-tune the model.\n",
    "\n",
    "### 3.2 Lasso (L1 reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso mean squared error for training: 10.2809\n",
      "Lasso mean squared error for evaluation: 10.8328\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_reg = Lasso(alpha=0.01)\n",
    "lasso_reg.fit(x_train, y_train)\n",
    "\n",
    "print('Lasso mean squared error for training: %.4f' % mean_squared_error(lasso_reg.predict(x_train), y_train))\n",
    "print('Lasso mean squared error for evaluation: %.4f' % mean_squared_error(lasso_reg.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Ridge (L2 reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge mean squared error for training: 10.2523\n",
      "Ridge mean squared error for evaluation: 10.8470\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_reg = Ridge(alpha=0.01, solver=\"cholesky\")\n",
    "ridge_reg.fit(x_train, y_train)\n",
    "\n",
    "print('Ridge mean squared error for training: %.4f' % mean_squared_error(ridge_reg.predict(x_train), y_train))\n",
    "print('Ridge mean squared error for evaluation: %.4f' % mean_squared_error(ridge_reg.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Elastic net (L1 and L2 reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic-net mean squared error for training: 10.2781\n",
      "Elastic-net mean squared error for evaluation: 10.8322\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic_net = ElasticNet(alpha=0.01, l1_ratio=0.1)\n",
    "elastic_net.fit(x_train, y_train)\n",
    "\n",
    "print('Elastic-net mean squared error for training: %.4f' % mean_squared_error(elastic_net.predict(x_train), y_train))\n",
    "print('Elastic-net mean squared error for evaluation: %.4f' % mean_squared_error(elastic_net.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model training: a classification problem\n",
    "\n",
    "This problem can also be interpreted as a classification problem, where each age (as 'rings' + 1.5 in the data) represents a class. Hence, we can build a series of classification models to verify the quality of models.\n",
    "\n",
    "### 4.1 Logistic regression\n",
    "First we build a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic reg mean squared error for training: 10.8710\n",
      "Logistic reg mean squared error for evaluation: 11.3577\n",
      "Logistic reg score: 0.1675\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_reg = LogisticRegression(max_iter=500, penalty='l2', multi_class='multinomial', solver='lbfgs')\n",
    "logistic_reg.fit(x_train, y_train)\n",
    "\n",
    "print('Logistic reg mean squared error for training: %.4f' % mean_squared_error(logistic_reg.predict(x_train), y_train))\n",
    "print('Logistic reg mean squared error for evaluation: %.4f' % mean_squared_error(logistic_reg.predict(x_test), y_test))\n",
    "\n",
    "score = logistic_reg.score(x_test, y_test)\n",
    "print('Logistic reg score: %.4f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar as before, we also run a cross-validation against this too. Also noted that due to the nature of multi-class job, we here prefer accuracy over f1_score, as the former is more self-representative when number of class if not intuitively known.\n",
    "\n",
    "Also, Sci-kit Learn would throw warnings when data set only contains a target/class with only one sample. Because we don't want to alter or drop any sample from data, we will just mute the warnings for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for accuracy:  [0.16352941 0.15576694 0.14885954 0.16646562 0.14927184]\n",
      "Accuracy: 0.16 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(logistic_reg, dftrain, dflabel, cv=5, scoring='accuracy')\n",
    "\n",
    "print('Scores for accuracy: ', scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After several times of attempt by tuning the parameters, including l1_reg, l2_reg, number of iterations and multi-class approaches, the score still seemed disappointing. It is possible that age of abalones doesn't have a linear relationship against the input features. Therefore, a non-linear model, like a tree, may be a better solution of this problem.\n",
    "\n",
    "### 4.2 Gradient boosted tree\n",
    "Gradient boosting ensembles weak prediction models, typically decision trees, in producing high-quality models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosted tree mean squared error for training: 0.0431\n",
      "Gradient boosted tree mean squared error for evaluation: 17.8469\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "params = {'n_estimators':300, 'max_depth':5, 'learning_rate':0.1, 'loss':'deviance'}\n",
    "gbtree_classifier = ensemble.GradientBoostingClassifier(**params)\n",
    "gbtree_classifier.fit(x_train, y_train)\n",
    "print('Gradient boosted tree mean squared error for training: %.4f'\n",
    "      % mean_squared_error(gbtree_classifier.predict(x_train), y_train))\n",
    "print('Gradient boosted tree mean squared error for evaluation: %.4f'\n",
    "      % mean_squared_error(gbtree_classifier.predict(x_test), y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is applied to this model too. Please be aware that MSE for training is 0! To reduce overfitting, we will take several actions as mentioned in the last part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for accuracy:  [0.12588235 0.12366231 0.11284514 0.13510253 0.12621359]\n",
      "Accuracy: 0.12 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(gbtree_classifier, dftrain, dflabel, cv=5, scoring='accuracy')\n",
    "\n",
    "print('Scores for accuracy: ', scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosted trees can easily get into overfitting issues. The example above shows one case of overfiting. To reduce overfitting, a number of actions have been taken, which included:\n",
    "\n",
    "1. Smaller learning rate.\n",
    "2. Stochastic gradient boosting (with subsample < 1).\n",
    "3. Minimize tree depth.\n",
    "4. Use of regularization.\n",
    "\n",
    "In the end, the optimal parameters were found as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient boosted tree mean squared error for training: 8.7953\n",
      "Gradient boosted tree mean squared error for evaluation: 11.7117\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators':500, 'subsample':0.5, 'max_depth':2, 'learning_rate':0.01, 'max_features':2, 'loss':'deviance'}\n",
    "gbtree_classifier = ensemble.GradientBoostingClassifier(**params)\n",
    "gbtree_classifier.fit(x_train, y_train)\n",
    "\n",
    "print('Gradient boosted tree mean squared error for training: %.4f'\n",
    "      % mean_squared_error(gbtree_classifier.predict(x_train), y_train))\n",
    "print('Gradient boosted tree mean squared error for evaluation: %.4f'\n",
    "      % mean_squared_error(gbtree_classifier.predict(x_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for accuracy:  [0.16470588 0.15219976 0.18127251 0.17852835 0.14927184]\n",
      "Accuracy: 0.17 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(gbtree_classifier, dftrain, dflabel, cv=5, scoring='accuracy')\n",
    "\n",
    "print('Scores for accuracy: ', scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
